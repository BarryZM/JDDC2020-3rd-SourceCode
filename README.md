## JDDC2020-3rd-SourceCode

#### JDDC2020第三名解决方案分享

作者：kitahara_kazusa、littleRain

2020年第三届智源-京东对话挑战大赛中（JDDC2020），我们团队有幸在众多优秀队伍中获得第三名。为了将比赛中踩过的坑、获得的经验以及感受到的一些体会分享给大家，我们写了这篇文档。另外，十分感谢主办方团队提供的数据集和提供的人工评测，给了大家在对话领域提高和学习的机会。

> http://jddc.jd.com/

简要介绍一下我们队伍的整体流程：我们根据上一年比赛中队伍写下的blog的经验，尝试了使用检索模型和生成模型做整体的召回，再通过一个打分模块对召回的内容排序，最终回复打分最高的回复。但是在实际操作的过程中，我们发现检索模型检索出来的效果不够准确，因此就放弃了检索模型，转而采用纯粹的生成模型做召回。

##### 一、比赛题目

​	JDDC比赛由智源-京东实验室主办，自2018年开始每年举办一次,至今年2020年已经是第三届了。观察每年比赛题目都是围绕京东客服咨询的多轮对话展开的，可以初步判断这个系列的比赛的目的是在像京东这样的电商平台的客服咨询环节，探索如何使用对话模型一定程度上取代真人客服，从而解放人工、减少人力成本。

​	今年的比赛聚焦于大规模零售场景下多模态的人机交互问题，目的在于研究如何在对话过程中融合使用多模态的用户信息。

###### 1.任务描述

​	针对多模态的对话场景（即对话session种用户提出的问题中至少包含一张图片信息），记录用户与客服之间的在线交互记录![](http://latex.codecogs.com/svg.latex?D={Q_0,A_0,Q_1,A_1,...,Q_n,A_n})，其中交互记录中![](http://latex.codecogs.com/svg.latex?Q_n)表示第n轮交互中用户提出的问题，![](http://latex.codecogs.com/svg.latex?A_n)表示第n轮交互中在线人工客服给出的回答，其中![](http://latex.codecogs.com/svg.latex?Q_n)或![](http://latex.codecogs.com/svg.latex?A_n)均可以包含多条消息，类别可能是纯文字消息、纯图片消息或图文混合消息；记录对话session涉及的背景知识B=ShopType, SkuId，其中背景知识中![](http://latex.codecogs.com/svg.latex?ShopType)表示商家类别信息（此次比赛涉及两个品类商家即小家电商家与服饰鞋靴商家），![](http://latex.codecogs.com/svg.latex?SkuId)表示此次对话中可能涉及的商品sku信息；此外，还提供一个简单地商品知识库![](http://latex.codecogs.com/svg.latex?KB=\{KB_{sku},...\})，可以通过![](http://latex.codecogs.com/svg.latex?sku)信息获取商品的基础属性信息。要求参赛系统对给定背景知识和多模态对话片段分析，给出满足用户需求的答案。目标是给出答案能够准确、完整、高效地回答用户的问题。

​	注：此次比赛仅关注纯文本形式的应答，即上下文信息或用户问题为多模态形式，预测应答为单模态形式。

###### 2.数据集

​	此次比赛的数据涉及小家电和服饰两个品类的用户和京东人工客服关于商品选购推荐、商品售后使用等覆盖电商购物场景售前、售中、售后各环节的真实场景对话数据。其中小家电品类，包含对话约13万session，每个session平均交互轮次约为7.3轮，共包含约95万轮对话，其中用户问题涉及约21.5万张图片；服饰品类，包含对话约11.6万session，其中每个session平均交互轮次约为7轮，共包含约81万轮对话，其中用户问题涉及约20万张图片。

###### 3.输入/输出

​	输入（上下文信息，用户问题）：此轮对话用户提出的问题![](http://latex.codecogs.com/svg.latex?Q_n)，其中![](http://latex.codecogs.com/svg.latex?Q_n)可能为纯文本、纯图片的问题或图文并茂的问题；此轮对话前n-1轮的对话历史信息，![](http://latex.codecogs.com/svg.latex?C={Q_0,A_0,Q_1,A_1,...,Q_{n-1},A_{n-1}})，历史对话信息也可能为多模态形式。

​	输出（文本预测答案）：根据输入信息，输出满足第n轮用户问题![](http://latex.codecogs.com/svg.latex?Q_n)所期望的答案，该答案应该是通顺、逻辑一致且含有丰富知识的问本回答。

<img src="https://github.com/kitaharatomoyo/JDDC2020-3rd-SourceCode/blob/main/dialog example.png" width="800" height="400" alt="小朋友你是否有很多问号"/><br/>

###### 评价方法

​	自动评测：参赛系统答案会和每个人工答案计算BLEU值，所有BLEU的均值作为产生答案的评价指标。

​	人工评测：人工会对参赛系统给出的第n轮回答对对话成功率进行考核。

​	模型评价：使用了多模态信息的模型得分更高。

​	最终评分：![](http://latex.codecogs.com/svg.latex?final\_score=0.3*BLEU+0.6*human\_score+0.1*model\_score)

##### 二、方案介绍

###### 图片信息的融合

对于图片信息，我们考虑图片中的文本信息是有用的，例如，如果图片中出现过“售后”、“退款”等信息，该图片就提示可能是售后退货这一场景；如果图片中出现过“收货“、”签收”、“运单”等信息，该图片就提示可能是用户等待物流这一场景。同时文本信息要么是手机截图、要么是快递单拍摄，可以比较方便地使用OCR获取。而其他信息却很难有效利用，例如，商品实物的图片，由于每个商品都各不相同，拍摄角度、拍摄距离各个不同，很难利用到这个信息；商品损坏程度的图片，很难识别到商品具体损坏的程度，因此我们就放弃了这一点，转而考虑更粗略地将图片进行分类，同时更多地用图片中的文本信息。

我们首先对所有图片进行了一个分类，分成了四组，分别是：需要进行OCR的图片，快递信息，商品页面截图，其他。我们手工标注了1390张图片，用来训练一个图片的分类器（ResNet）。然后对需要进行OCR的图片进行OCR，并对OCR的结果进行过滤。OCR的结果分为4类：detail、combination（当OCR的结果包含以下文字则保留全部结果）、extraction（OCR的结果只保留以下文字）、transformation（当OCR的结果出现以下文字，进行转换）、其他（当OCR的结果不符合前面的条件，则保留tf-idf值较高的字段）。

```
    ocr_phrase = {
        'detail': [
            '交易纠纷详情', '取消退款进度', '评价详情', '商品评价', '评价中心', '问题详情', 
            '进度详情', '服务单详情', '投诉', '保单详情', '晒图相册'
        ],
        'combination': ['请输入 问题', '联系 客服', '已 发货', '价 保', '输入 手机号码'],
        'extraction': [
            '填写订单', '尺码', '运单详情', '电子存根', '签收底单', '发货清单', '增票资质',
            '交易物流', '订单详情', '等待收货', '自提点', '正在出库', '暂时无货', '送达时间', 
            '支付成功', '付款成功', '等待付款', '正在配送途中', '错过售后申请时效', '已签收', 
            '取件码', '不支持取消', '超出可购买总量', '京东收银台', '已限制购买数量', 
            '超过了限购件数', '确认订单', '订单跟踪', '售后申请', '换货', '申请售后', 
            '申请退款', '重新提交', '退换', '退换售后', '取件', '售后', '上传快递单号', 
            '验证码', '保修期限', '已退款', '无货', '去结算', '审核未通过', '评价成功', 
            '更改发货单', '未查到运单信息', '支付尾款', '选择售后类型', '购物车', 
            '快递单号查询', '订购单', '新增收件人信息' '请输入正确的联系方式', '无货或不支持配送'
        ],
        'transformation': [
        	{'退款明细 再次购买 卖了换钱 追加评价 查看发票 需付款': '订单截图'}, 
        	{'颜色 数量 保障服务 确认': '加购物车选择配置'}, 
        	{'全部分类 综合推荐 价格区间 筛选': '商品截图'}
        ]
    }
```

###### 检索模型

对于一个测试集中的<utterance, question>，如果训练集中有相同或相似的<utterance,quesiton>出现过，那么我们将那个最相似的<utterance, question>的回复视为当前问题的回复。

由于utterance很长，而越靠近当前question的sentence对回复的影响越大，越早的sentence对回复的影响越小，因此我们仅使用了question及之前一句的sentence。

表征问题的方式是使用DSSM双塔模型：

<img src="https://github.com/kitaharatomoyo/JDDC2020-3rd-SourceCode/blob/main/DSSM.png" width="400" height="400" alt="小朋友你是否有很多问号"/><br/>

在训练集上，将一组<utterance,question>与<response>分别使用表征层（bert）表征后得到两个表征向量，然后经过匹配层得到匹配得分，同时随机采样其他的<response>作为负例。训练完成后将所有的<utterance,question>的表征向量离线保存下来。

在测试集上，将当前询问的<utterance,question>经过已训练好的表征模型得到其表征向量，使用向量索引库找到训练集中最相似的（topK）表征向量，然后将其对应的回复作为候选回复。

向量索引使用的faiss库，一个facebook开源的向量索引库。

然而最后实验下来，检索模型的效果没有预想的好，仅能得到0.03左右的BLEU值，因此最终我们放弃了使用检索模型。

###### 生成模型

我们使用了GPT-2模型作为LM，同时在模型上添加了两个对话任务上的信息：

1. 说话人信息（token type）：在对话中我们可以知道每一句话分别是谁说的。（对属于同一对话角色的对话进行标记）
2. 轮次信息（turn type）：在对话中我们可以知道每一个回答对应的是哪一个问题。（对属于同一对话轮次的的对话进行标记）

<img src="https://github.com/kitaharatomoyo/JDDC2020-3rd-SourceCode/blob/main/GPT-2.png" width="900" height="350" alt="小朋友你是否有很多问号"/><br/>

我们通过生成模型获得若干候选回复。

###### 打分模型

我们训练了一个打分模型：逆序拼接<utterance,question,response>，拼接结果为<response+question+utterance[-1]+utterance[-2]+...+utterance[2]+utterance[1]>，输入GPT-2模型，将模型的loss视为打分分数，选择所有候选回复中loss最小的一个。

<img src="https://github.com/kitaharatomoyo/JDDC2020-3rd-SourceCode/blob/main/mmi-model.png" width="900" height="200" alt="小朋友你是否有很多问号"/><br/>

##### 三、比赛结果

最后我们的模型获得了初赛第二（BLEU值），决赛第三的成绩。与主办方讨论后，得到的结果是人工评测任务完成率不够，只有0.42，第一名有0.49，第二第三名有0.46，我们还差得比较大（人工评测一共1000条数据）。

Todo：具体模型差距在什么地方？听完报告后再来补全。

<img src="https://github.com/kitaharatomoyo/JDDC2020-3rd-SourceCode/blob/main/初赛成绩.png" width="600" height="600" alt="小朋友你是否有很多问号"/><br/>

本次比赛我们队伍学到了很多，这是我们第一次参加评测，从一开始的检索方案，到生成方案，到最后各种加trick各种玄学调参，这中间的过程学到了很多。一个比较大的收获是学到了很多比赛的方法和技巧，包括bm25、DSSM（虽然最后没用上）、faiss库、如何加入很多规则，重写了很多模型，看了很多huggingface/transformers的实现；第二个是学到了做比赛的或者说做项目的方法：如何制定远期计划、要定时开会、会议上要将任务分配给个人并给出ddl、要建立提交库来方便记录与进行对比实验、代码的保存分类要系统。
